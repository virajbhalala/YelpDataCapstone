{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys  \n",
    "import re\n",
    "import sklearn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "import re  # For preprocessing\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hygiene_text_path= \"../data/Hygiene/hygiene.dat\"\n",
    "hygiene_labels_path= \"../data/Hygiene/hygiene.dat.labels\"\n",
    "hygiene_others_path= \"../data/Hygiene/hygiene.dat.additional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hygiene_text_path) as f:\n",
    "    arrText = [l.rstrip() for l in f]\n",
    "with open(hygiene_labels_path) as f:\n",
    "    arrLabels = [l.rstrip() for l in f]\n",
    "\n",
    "df = pd.DataFrame({'text':arrText, 'labels':arrLabels})\n",
    "hygiene_others = pd.read_csv(hygiene_others_path, names=[\"cuisines\", \"zipcode\", \"reviews\", \"avg_ratings\"])\n",
    "df = df.join(hygiene_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.cuisines = [ast.literal_eval(x) for x in df.cuisines]\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "res = pd.DataFrame(mlb.fit_transform(df.cuisines),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=df.cuisines.index)\n",
    "df = df.drop(\"cuisines\", axis =1)\n",
    "df = df.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model without using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"labels\"] != \"[None]\" ]\n",
    "test_df = df[df[\"labels\"] == \"[None]\" ]\n",
    "X_train, y_train =train_df.drop(['text', 'labels', \"zipcode\"], axis=1), train_df[\"labels\"]\n",
    "X_test, y_test =test_df.drop(['text', 'labels', \"zipcode\"], axis=1), test_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# dtrain = xgb.DMatrix(np.array(X_train), label=np.array(y_train))\n",
    "# dtest = xgb.DMatrix(np.array(X_test))\n",
    "# param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "# param['nthread'] = 4\n",
    "# param['eval_metric'] = 'auc'\n",
    "# bst = xgb.train(param, dtrain, 10)\n",
    "# y_pred = bst.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(np.array(X_train), np.array(y_train))\n",
    "y_pred = model.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./baseline_predictions.out', y_pred, fmt='%s')\n",
    "with open('./baseline_predictions.out', 'r') as original: data = original.read()\n",
    "with open('./baseline_predictions.out', 'w') as modified: modified.write(\"Viraj Bhalala(vbb2)\\n\" + data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1: 0.6659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)\n",
    "    \n",
    "    \n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UtilWordEmbedding import DocPreprocess\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "all_docs = DocPreprocess(nlp, stop_words, df['text'], df['labels'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "dir_path = \"./\"\n",
    "# Save all_docs as pickle.\n",
    "with open(os.path.join(dir_path, 'all_docs.pickle'), 'wb') as f:\n",
    "    pickle.dump(all_docs, f, pickle.HIGHEST_PROTOCOL)\n",
    "# Read pickle.\n",
    "with open(os.path.join(dir_path, 'all_docs.pickle'), 'rb') as f:\n",
    "    all_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13299, (13299, 104))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs.tagdocs), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['worry', 'review', 'place', 'strongly', 'think', 'bad', 'night', 'place', 'lot', 'better', 'mexican', 'food', 'place', 'run', 'avocado', 'vegetarian', 'friend', 'order', 'meatless', 'dish', 'rely', 'heavily', 'avocado', 'minute', 'order', 'drool', 'expect', 'eat', 'waitress', 'approach', 'table', 'tell', 'bad', 'news', 'bad', 'dish', 'order', 'table', 'people', 'include', 'avocado', 'service', 'little', 'slow', 'waitress', 'wasn', 'friendly', 'helpful', 'food', 'arrive', 'people', 'wait', 'minute', 'plate', 'eat', 'get', 'bad', 'awkward', 'large', 'group', 'come', 'pay', 'bill', 'sit', 'group', 'decide', 'service', 'didn', 'tip', 'ask', 'split', 'tab', 'way', 'large', 'group', 'waitress', 'huff', 'puff', 'roller', 'eye', 'say', 'usually', 'not', 'calculate', 'tip', 'head', 'door', 'catch', 'guard', 'shout', 'direction', 'turn', 'waitress', 'approach', 'say', 'tip', 'wasn', 'large', 'insult', 'feel', 'money', 'grant', 'embarrassed', 'ask', 'size', 'group', 'gratuity', 'add', 'bill', 'give', 'little', 'don', 'know', 'trouble', 'math', 'misread', 'bill', 'literally', 'ask', 'big', 'tip', 'especially', 'couldn', 'complete', 'order', 'serve', 'food', 'food', 'wasn', 'terrible', 'don', 'think', 'nice', 'atmosphere', 'old', 'house', 'phinney', 'ridge', 'area', 'eat', 'taco', 'absolutely', 'delicious', 'selection', 'homemade', 'salsas', 'great', 'nice', 'place', 'margarita', 'listen', 'punk', 'country', 'jukebox', 'chill', 'look', 'forward', 'hang', 'porch', 'summertime', 'fast', 'review', 'dine', 'taco', 'fake', 'meat', 'tasty', 'bartender', 'margarita', 'taste', 'normal', 'marg', 'strong', 'lack', 'pom', 'juice', 'pineapple', 'salsa', 'delicious', 'chunky', 'pineapple', 'salsa', 'delicious', 'chip', 'crispy', 'bad', 'stale', 'chip', 'restaurant', 'edit', 'change', 'star', 'wasn', 'fabulous', 'way', 'crowded', 'super', 'enjoyable', 'atmosphereit', 'busy', 'go', 'friday', 'evening', 'seat', 'arrangement', 'improve', 'unfortunately', 'sit', 'busy', 'walkway', 'bump', 'bit', 'wish', 'chupacabra', 'stuff', 'maybe', 'story', 'menu', 'miss', 'whoop', 'single', 'sad', 'little', 'bat', 'hang', 'ceiling', 'enjoy', 'company', 'friendly', 'goat', 'eat', 'chupacabra', 'festive', 'want', 'carnage', 'dine', 'maybe', 'butcher', 'paper', 'table', 'paper', 'placemat', 'patron', 'draw', 'chupacabra', 'picture', 'chupacabra', 'el', 'chupacabra', 'cozy', 'fun', 'atmosphere', 'crowd', 'reservation', 'wait', 'list', 'sign', 'great', 'margarita', 'affordable', 'tasty', 'food', 'good', 'vegetarian', 'omnivore', 'alike', 'stop', 'check', 'small', 'busy', 'list', 'rarely', 'actually', 'pay', 'attention', 'waitress', 'care', 'attitude', 'beer', 'cold', 'food', 'doesn', 'cause', 'salmonella', 'people', 'waitress', 'little', 'attentive', 'don', 'away', 'star', 'add', 'good', 'tattoo', 'low', 'expectation', 'word', 'mouth', 'want', 'chip', 'salsa', 'stat', 'guac', 'stat', 'margs', 'stat', 'bring', 'triple', 'threat', 'hard', 'furrowed', 'brow', 'face', 'need', 'food', 'need', 'casual', 'get', 'cool', 'little', 'house', 'greenwood', 'porch', 'patio', 'indoor', 'decor', 'scream', 'dia', 'muertos', 'share', 'taco', 'shrimp', 'order', 'special', 'smoked', 'salmon', 'shrimp', 'runner', 'fave', 'unpredictably', 'spicy', 'bite', 'nice', 'tasty', 'little', 'shrunken', 'sucker', 'hard', 'find', 'salmon', 'hand', 'smack', 've', 'salmon', 'taco', 'awesome', 'avocado', 'addition', 'veggie', 'love', 'service', 'perfectly', 'punctual', 'waitress', 'stylish', 'friendly', 'margarita', 'refreshing', 'tasty', 'strong', 'bode', 'out', 'overall', 'good', 'dinner', 'recommend', 'low', 'key', 'fun', 'lively', 'night', 'bad', 'food', 'pretty', 'good', 'service', 'fine', 'decent', 'price', 'atmosphere', 'interesting', 'big', 'fan', 'place', 'great', 'location', 'bartender', 'friendly', 'jukebox', 'favorite', 'time', 'fill', 'punk', 'metal', 'don', 'food', 'great', 'order', 'carne', 'asada', 'burrito', 'friggin', 'love', 'cheap', 'drink', 'happy', 'hour', 'late', 'night', 'special', 'himsa', 'rip', 've', 'good', 'time', 'bring', 'star', 'especially', 'think', 'time', 'past', 'seriously', 'doubt', 'come', 'anymore', 'know', 'mexican', 'place', 'close', 'home', 'el', 'chupa', 'fact', 'time', 've', 'want', 'don', 'wrong', 'food', 'bad', 'great', 'well', 'food', 'atmosphere', 'dandy', 've', 'like', 'coziness', 'decor', 'warm', 'day', 'pleasant', 'inside', 'door', 'open', 'deck', 'outside', 'drink', 'real', 'ass', 'kicker', 'realize', 'margarita', 'cut', 'blame', 'fact', 've', 'find', 'margarita', 'taste', 'good', 'el', 'chupa', 'doesn', 'stand', 'chance', 'past', 'sheer', 'alcohol', 'hold', 'couple', 'time', 'yesterday', 'try', 'mojito', 'fine', 'taste', 'tasty', 'certainly', 'alcohol', 'service', 'wasn', 'horrible', 'start', 'bumpily', 'lunchmate', 'simultaneously', 'wtf', 'moment', 'aloud', 'table', 'visit', 'server', 'time', 'wait', 'patiently', 'fold', 'menu', 'order', 'take', 'show', 'pretty', 'timely', 'fashion', 'arrive', 'time', 'order', 'special', 'time', 'order', 'take', 'clock', 'come', 'go', 'special', 'sum', 'suppose', 'want', 'wouldn', 'bother', 'sorry', 'chupacabra', 'honeymoon', 'place', 'try', 'lot', 'fun', 'watch', 'crowd', 'food', 'good', 'homemade', 'sauce', 'find', 'table', 'chip', 'nachos', 'world', 'wish', 'sell', 'home', 'use', 'actually', 'deck', 'spring', 'summer', 'early', 'fall', 'especially', 'hot', 'summer', 'day', 'great', 'wait', 'time', 'popular', 'cold', 'beer', 'great', 'food', 'wrong', 'price', 'reasonable', 'fun', 'atmosphere', 'come', 'expect', 'college', 'area', 'don', 'mean', 'negatively', 'crowd', 'look', 'young', 'professional', 'staff', 'friendly', 'service', 'quick', 'food', 'good', 'amazing', 'mexican', 'food', 'margarita', 'good', 'complaint', 'dessert', 'fry', 'tortilla', 'cinnamon', 'honey', 'good', 'hadn', 'particular', 'dessert', 'maybe', 'don', 'dessert', 'definitely', 'wouldn', 'order', 'star', 'time', 'favorite', 'mexican', 'food', 'joint', 'chipotle', 'el', 'chupacabre', 'chipotle', 'mcdonald', 'own', 'chain', 'locate', 'mile', 'house', 'el', 'chupe', 'indepentantly', 'own', 'locate', 'neighborhood', 'pick', 'later', 'good', 'pool', 'free', 'jukebox', 'tecate', 'great', 'selection', 'hot', 'sauce', 'good', 'price', 'sure', 'burrito', 'love', 'place', 'good', 'rating', 'service', 'terrible', 'order', 'wrong', 'time', 'mean', 'order', 'wait', 'patiently', 'friend', 'nom', 'away', 'tasty', 'burrito', 'clear', 'server', 'item', 'order', 'food', 'allergy', 'bring', 'burrito', 'fill', 'ingredient', 'eat', 'problem', 'burritos', 'menu', 'oddly', 'name', 'basic', 'regular', 'suspiciously', 'close', 'synonym', 'think', 'new', 'item', 'name', 'help', 'order', 'basic', 'regular', 'serve', 'give', 'star', 'wait', 'minute', 'burrito', 'isn', 'big', 'deal', 'night', 'kicker', 'boyfriend', 'order', 'fake', 'meat', 'burrito', 'takeout', 'tell', 'fake', 'meat', 'say', 'meatless', 'fine', 'get', 'burrito', 'label', 'meat', 'ride', 'bike', 'home', 'hand', 'burrito', 'unwrapped', 'pleasantly', 'surprised', 'find', 'stuff', 'chicken', 'eat', 'meat', 'toss', 'bummer', 'absolutely', 'adore', 'food', 'marg', 'fake', 'meat', 'good', 'need', 'step', 'game', 'far', 'service', 'go', 'great', 'place', 'come', 'anytime', 'vote', 'star', 'guess', 'come', 'enjoy', 'company', 'food', 'go', 'complain', 'service', 'place', 'pay', 'join', 'crowd', 'fast', 'food', 'crap', 'shack', 'food', 'great', 'home', 'sauce', 'good', 'love', 'barrel', 'salsa', 'pine', 'apple', 'low', 'key', 'inexpensive', 'delicious', 'mexican', 'food'], tags=[2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs.tagdocs[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build word embedding using Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = multiprocessing.cpu_count()\n",
    "word_model = Word2Vec(all_docs.doc_words,\n",
    "                      min_count=2,\n",
    "                      size=100,\n",
    "                      window=5,\n",
    "                      workers=workers,\n",
    "                      iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38977, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.7647111 , -0.73086184, -1.2468382 , -1.0027946 , -0.96313715,\n",
       "        0.9111134 ,  0.65977895,  3.5456011 , -0.02235585,  1.6440451 ,\n",
       "       -0.0661039 ,  0.41211852, -0.19577555,  0.1812265 ,  1.5138743 ,\n",
       "        0.02916883,  0.4625483 , -1.3284774 , -0.45937747, -1.6949239 ,\n",
       "        1.2153699 ,  4.196206  , -0.50019646,  0.48818356, -0.6409747 ,\n",
       "        1.5496792 ,  1.1308266 , -2.791238  , -0.7878722 ,  1.9967105 ,\n",
       "       -2.0945165 ,  2.8918045 , -2.4257357 , -0.78464067, -2.8459082 ,\n",
       "        4.979463  , -2.870692  ,  1.8776709 , -0.87444013, -0.9911716 ,\n",
       "       -4.8545923 , -0.29963732,  0.27686313, -2.1057916 ,  1.8179989 ,\n",
       "        1.1317976 ,  1.8244607 , -2.3895843 ,  1.934337  , -0.9373677 ,\n",
       "        2.4383726 ,  1.4679741 , -0.45419896, -0.39970812, -1.4040339 ,\n",
       "        0.5939909 ,  0.5153689 ,  0.71926403,  1.5762645 , -0.29474178,\n",
       "       -0.35648167,  0.00639748,  1.3986342 ,  0.8788819 , -0.4781381 ,\n",
       "        3.0308967 ,  1.1946028 , -0.2747328 ,  2.299122  ,  0.2637879 ,\n",
       "        0.07607791,  1.365188  , -0.55783033, -2.1623447 ,  1.6285464 ,\n",
       "       -0.7563248 ,  2.9683392 , -0.20913929,  0.05560299,  0.6553585 ,\n",
       "        0.09101417, -0.39400128, -0.70904267, -2.427884  ,  0.21857798,\n",
       "        0.8122631 ,  0.32033026,  0.79379797,  0.12037044,  0.6374975 ,\n",
       "        0.5543785 , -0.4400709 ,  4.591583  ,  2.1465614 ,  0.00992613,\n",
       "       -2.4494958 , -0.30629474, -1.6794864 , -0.50620145, -0.17750408],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.wv.syn0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## averaging word embedding in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute average owing to no vector for []\n"
     ]
    }
   ],
   "source": [
    "from UtilWordEmbedding import MeanEmbeddingVectorizer\n",
    "\n",
    "mean_vec_tr = MeanEmbeddingVectorizer(word_model)\n",
    "doc_vec = mean_vec_tr.transform(all_docs.doc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13299, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(dir_path,'doc_vec.csv'), doc_vec, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding_df = df.join(pd.DataFrame(doc_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = mean_embedding_df[mean_embedding_df[\"labels\"] != \"[None]\" ]\n",
    "test_df = mean_embedding_df[mean_embedding_df[\"labels\"] == \"[None]\" ]\n",
    "X_train, y_train =train_df.drop(['text', 'labels', 'zipcode'], axis=1), train_df[\"labels\"]\n",
    "X_test, y_test =test_df.drop(['text', 'labels', 'zipcode'], axis=1), test_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(np.array(X_train), label=np.array(y_train))\n",
    "dtest = xgb.DMatrix(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=1000)\n",
    "model.fit(np.array(X_train), np.array(y_train))\n",
    "y_pred = model.predict(np.array(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 6, 'eta': 0.3, 'objective': 'binary:logistic', 'subsample':0.8, \"n_estimators\":20000}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "bst = xgb.train(param, dtrain)\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred = np.where(y_pred > 0.95, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./average_word2vec_predictions.out', y_pred, fmt='%s')\n",
    "with open('./average_word2vec_predictions.out', 'r') as original: data = original.read()\n",
    "with open('./average_word2vec_predictions.out', 'w') as modified: modified.write(\"Viraj Bhalala(vbb2)\\n\" + data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 202)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1: 0.7027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.6929 - binary_accuracy: 0.5110\n",
      "Epoch 2/100\n",
      "546/546 [==============================] - 0s 43us/step - loss: 0.6927 - binary_accuracy: 0.5348\n",
      "Epoch 3/100\n",
      "546/546 [==============================] - 0s 41us/step - loss: 0.6928 - binary_accuracy: 0.5092\n",
      "Epoch 4/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6927 - binary_accuracy: 0.5055\n",
      "Epoch 5/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6925 - binary_accuracy: 0.5110\n",
      "Epoch 6/100\n",
      "546/546 [==============================] - 0s 42us/step - loss: 0.6925 - binary_accuracy: 0.5055\n",
      "Epoch 7/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6922 - binary_accuracy: 0.5128\n",
      "Epoch 8/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6920 - binary_accuracy: 0.5073\n",
      "Epoch 9/100\n",
      "546/546 [==============================] - 0s 40us/step - loss: 0.6919 - binary_accuracy: 0.5183\n",
      "Epoch 10/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6914 - binary_accuracy: 0.5092\n",
      "Epoch 11/100\n",
      "546/546 [==============================] - 0s 40us/step - loss: 0.6919 - binary_accuracy: 0.5128\n",
      "Epoch 12/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6913 - binary_accuracy: 0.5366\n",
      "Epoch 13/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6906 - binary_accuracy: 0.5385\n",
      "Epoch 14/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6895 - binary_accuracy: 0.5549\n",
      "Epoch 15/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6885 - binary_accuracy: 0.5586\n",
      "Epoch 16/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6882 - binary_accuracy: 0.5549\n",
      "Epoch 17/100\n",
      "546/546 [==============================] - 0s 35us/step - loss: 0.6874 - binary_accuracy: 0.5696\n",
      "Epoch 18/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6872 - binary_accuracy: 0.5751\n",
      "Epoch 19/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6855 - binary_accuracy: 0.5788\n",
      "Epoch 20/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6838 - binary_accuracy: 0.5916\n",
      "Epoch 21/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6847 - binary_accuracy: 0.5934\n",
      "Epoch 22/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6830 - binary_accuracy: 0.5989\n",
      "Epoch 23/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6807 - binary_accuracy: 0.6154\n",
      "Epoch 24/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6776 - binary_accuracy: 0.6081\n",
      "Epoch 25/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6801 - binary_accuracy: 0.6172\n",
      "Epoch 26/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6773 - binary_accuracy: 0.6337\n",
      "Epoch 27/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6763 - binary_accuracy: 0.6319\n",
      "Epoch 28/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6769 - binary_accuracy: 0.6300\n",
      "Epoch 29/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.6669 - binary_accuracy: 0.6300\n",
      "Epoch 30/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.6638 - binary_accuracy: 0.6355\n",
      "Epoch 31/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6673 - binary_accuracy: 0.6300\n",
      "Epoch 32/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6689 - binary_accuracy: 0.6319\n",
      "Epoch 33/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6662 - binary_accuracy: 0.6392\n",
      "Epoch 34/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6576 - binary_accuracy: 0.6374\n",
      "Epoch 35/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6638 - binary_accuracy: 0.6484\n",
      "Epoch 36/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6483 - binary_accuracy: 0.6557\n",
      "Epoch 37/100\n",
      "546/546 [==============================] - 0s 44us/step - loss: 0.6543 - binary_accuracy: 0.6557\n",
      "Epoch 38/100\n",
      "546/546 [==============================] - 0s 45us/step - loss: 0.6463 - binary_accuracy: 0.6630\n",
      "Epoch 39/100\n",
      "546/546 [==============================] - 0s 42us/step - loss: 0.6456 - binary_accuracy: 0.6593\n",
      "Epoch 40/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6394 - binary_accuracy: 0.6630\n",
      "Epoch 41/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6412 - binary_accuracy: 0.6557\n",
      "Epoch 42/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6399 - binary_accuracy: 0.6593\n",
      "Epoch 43/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6312 - binary_accuracy: 0.6722\n",
      "Epoch 44/100\n",
      "546/546 [==============================] - 0s 40us/step - loss: 0.6343 - binary_accuracy: 0.6722\n",
      "Epoch 45/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6255 - binary_accuracy: 0.6722\n",
      "Epoch 46/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6284 - binary_accuracy: 0.6795\n",
      "Epoch 47/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6323 - binary_accuracy: 0.6648\n",
      "Epoch 48/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6188 - binary_accuracy: 0.6777\n",
      "Epoch 49/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6243 - binary_accuracy: 0.6905\n",
      "Epoch 50/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6231 - binary_accuracy: 0.6923\n",
      "Epoch 51/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6305 - binary_accuracy: 0.6777\n",
      "Epoch 52/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6258 - binary_accuracy: 0.6850\n",
      "Epoch 53/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6157 - binary_accuracy: 0.6886\n",
      "Epoch 54/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6235 - binary_accuracy: 0.6740\n",
      "Epoch 55/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.6217 - binary_accuracy: 0.6850\n",
      "Epoch 56/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6276 - binary_accuracy: 0.6868\n",
      "Epoch 57/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6209 - binary_accuracy: 0.6886\n",
      "Epoch 58/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6148 - binary_accuracy: 0.6960\n",
      "Epoch 59/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6187 - binary_accuracy: 0.6960\n",
      "Epoch 60/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6109 - binary_accuracy: 0.6905\n",
      "Epoch 61/100\n",
      "546/546 [==============================] - 0s 48us/step - loss: 0.6190 - binary_accuracy: 0.6960\n",
      "Epoch 62/100\n",
      "546/546 [==============================] - 0s 45us/step - loss: 0.6122 - binary_accuracy: 0.6868\n",
      "Epoch 63/100\n",
      "546/546 [==============================] - 0s 41us/step - loss: 0.6170 - binary_accuracy: 0.6905\n",
      "Epoch 64/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6253 - binary_accuracy: 0.6941\n",
      "Epoch 65/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6119 - binary_accuracy: 0.7051\n",
      "Epoch 66/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6102 - binary_accuracy: 0.6941\n",
      "Epoch 67/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6138 - binary_accuracy: 0.6868\n",
      "Epoch 68/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6133 - binary_accuracy: 0.6923\n",
      "Epoch 69/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.6050 - binary_accuracy: 0.6978\n",
      "Epoch 70/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6074 - binary_accuracy: 0.6960\n",
      "Epoch 71/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.6105 - binary_accuracy: 0.6832\n",
      "Epoch 72/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6067 - binary_accuracy: 0.6923\n",
      "Epoch 73/100\n",
      "546/546 [==============================] - 0s 42us/step - loss: 0.6094 - binary_accuracy: 0.6758\n",
      "Epoch 74/100\n",
      "546/546 [==============================] - 0s 40us/step - loss: 0.6064 - binary_accuracy: 0.6960\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/546 [==============================] - 0s 38us/step - loss: 0.6109 - binary_accuracy: 0.6978\n",
      "Epoch 76/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6067 - binary_accuracy: 0.6813\n",
      "Epoch 77/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6097 - binary_accuracy: 0.7015\n",
      "Epoch 78/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.6146 - binary_accuracy: 0.6960\n",
      "Epoch 79/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.5998 - binary_accuracy: 0.7033\n",
      "Epoch 80/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.5944 - binary_accuracy: 0.6978\n",
      "Epoch 81/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6039 - binary_accuracy: 0.6960\n",
      "Epoch 82/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6148 - binary_accuracy: 0.7070\n",
      "Epoch 83/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6004 - binary_accuracy: 0.6923\n",
      "Epoch 84/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6011 - binary_accuracy: 0.6886\n",
      "Epoch 85/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.5977 - binary_accuracy: 0.6996\n",
      "Epoch 86/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.5881 - binary_accuracy: 0.7088\n",
      "Epoch 87/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.5940 - binary_accuracy: 0.6996\n",
      "Epoch 88/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.5869 - binary_accuracy: 0.6978\n",
      "Epoch 89/100\n",
      "546/546 [==============================] - 0s 35us/step - loss: 0.5965 - binary_accuracy: 0.7070\n",
      "Epoch 90/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.5872 - binary_accuracy: 0.6960\n",
      "Epoch 91/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.5922 - binary_accuracy: 0.7088\n",
      "Epoch 92/100\n",
      "546/546 [==============================] - 0s 35us/step - loss: 0.5891 - binary_accuracy: 0.7143\n",
      "Epoch 93/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.5872 - binary_accuracy: 0.7015\n",
      "Epoch 94/100\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.5979 - binary_accuracy: 0.6978\n",
      "Epoch 95/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.5927 - binary_accuracy: 0.6978\n",
      "Epoch 96/100\n",
      "546/546 [==============================] - 0s 40us/step - loss: 0.5768 - binary_accuracy: 0.6996\n",
      "Epoch 97/100\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.5852 - binary_accuracy: 0.7051\n",
      "Epoch 98/100\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.5761 - binary_accuracy: 0.7106\n",
      "Epoch 99/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.5781 - binary_accuracy: 0.7088\n",
      "Epoch 100/100\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.5793 - binary_accuracy: 0.7051\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=201, activation='linear', kernel_initializer= \"random_uniform\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation='linear', kernel_initializer= \"random_uniform\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50, activation='linear', kernel_initializer= \"random_uniform\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='linear', kernel_initializer= \"random_uniform\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer= \"random_uniform\", bias_initializer='zeros'))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[\"binary_accuracy\"])\n",
    "\n",
    "\n",
    "model.fit(np.array(X_train, dtype=np.float32),np.array(y_train, dtype=np.float32) , epochs=100, batch_size=64)\n",
    "y_pred = model.predict(np.array(X_test, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "np.savetxt('./average_word2vec_predictions_dl.out', y_pred, fmt='%s')\n",
    "with open('./average_word2vec_predictions_dl.out', 'r') as original: data = original.read()\n",
    "with open('./average_word2vec_predictions_dl.out', 'w') as modified: modified.write(\"Viraj Bhalala(vbb2)\\n\" + data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
