{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys  \n",
    "import re\n",
    "import sklearn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "import re  # For preprocessing\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hygiene_text_path= \"../data/Hygiene/hygiene.dat\"\n",
    "hygiene_labels_path= \"../data/Hygiene/hygiene.dat.labels\"\n",
    "hygiene_others_path= \"../data/Hygiene/hygiene.dat.additional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hygiene_text_path) as f:\n",
    "    arrText = [l.rstrip() for l in f]\n",
    "with open(hygiene_labels_path) as f:\n",
    "    arrLabels = [l.rstrip() for l in f]\n",
    "\n",
    "df = pd.DataFrame({'text':arrText, 'labels':arrLabels})\n",
    "hygiene_others = pd.read_csv(hygiene_others_path, names=[\"cuisines\", \"zipcode\", \"reviews\", \"avg_ratings\"])\n",
    "df = df.join(hygiene_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.cuisines = [ast.literal_eval(x) for x in df.cuisines]\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "res = pd.DataFrame(mlb.fit_transform(df.cuisines),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=df.cuisines.index)\n",
    "df = df.drop(\"cuisines\", axis =1)\n",
    "df = df.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model without using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"labels\"] != \"[None]\" ]\n",
    "test_df = df[df[\"labels\"] == \"[None]\" ]\n",
    "X_train, y_train =train_df.drop(['text', 'labels', \"zipcode\"], axis=1), train_df[\"labels\"]\n",
    "X_test, y_test =test_df.drop(['text', 'labels', \"zipcode\"], axis=1), test_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(np.array(X_train), label=np.array(y_train))\n",
    "dtest = xgb.DMatrix(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "bst = xgb.train(param, dtrain, 10)\n",
    "y_pred = bst.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier()\n",
    "# model.fit(np.array(X_train), np.array(y_train))\n",
    "# y_pred = model.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./baseline_predictions.out', y_pred, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precission @0.6 : 0.6676\n",
    "- Recall @0.4: 0.6634\n",
    "- F1: 0.6659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)\n",
    "    \n",
    "    \n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UtilWordEmbedding import DocPreprocess\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "all_docs = DocPreprocess(nlp, stop_words, df['text'], df['labels'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "dir_path = \"./\"\n",
    "# Save all_docs as pickle.\n",
    "with open(os.path.join(dir_path, 'all_docs.pickle'), 'wb') as f:\n",
    "    pickle.dump(all_docs, f, pickle.HIGHEST_PROTOCOL)\n",
    "# Read pickle.\n",
    "with open(os.path.join(dir_path, 'all_docs.pickle'), 'rb') as f:\n",
    "    all_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13299, (13299, 104))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs.tagdocs), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['worry', 'review', 'place', 'strongly', 'think', 'bad', 'night', 'place', 'lot', 'better', 'mexican', 'food', 'place', 'run', 'avocado', 'vegetarian', 'friend', 'order', 'meatless', 'dish', 'rely', 'heavily', 'avocado', 'minute', 'order', 'drool', 'expect', 'eat', 'waitress', 'approach', 'table', 'tell', 'bad', 'news', 'bad', 'dish', 'order', 'table', 'people', 'include', 'avocado', 'service', 'little', 'slow', 'waitress', 'wasn', 'friendly', 'helpful', 'food', 'arrive', 'people', 'wait', 'minute', 'plate', 'eat', 'get', 'bad', 'awkward', 'large', 'group', 'come', 'pay', 'bill', 'sit', 'group', 'decide', 'service', 'didn', 'tip', 'ask', 'split', 'tab', 'way', 'large', 'group', 'waitress', 'huff', 'puff', 'roller', 'eye', 'say', 'usually', 'not', 'calculate', 'tip', 'head', 'door', 'catch', 'guard', 'shout', 'direction', 'turn', 'waitress', 'approach', 'say', 'tip', 'wasn', 'large', 'insult', 'feel', 'money', 'grant', 'embarrassed', 'ask', 'size', 'group', 'gratuity', 'add', 'bill', 'give', 'little', 'don', 'know', 'trouble', 'math', 'misread', 'bill', 'literally', 'ask', 'big', 'tip', 'especially', 'couldn', 'complete', 'order', 'serve', 'food', 'food', 'wasn', 'terrible', 'don', 'think', 'nice', 'atmosphere', 'old', 'house', 'phinney', 'ridge', 'area', 'eat', 'taco', 'absolutely', 'delicious', 'selection', 'homemade', 'salsas', 'great', 'nice', 'place', 'margarita', 'listen', 'punk', 'country', 'jukebox', 'chill', 'look', 'forward', 'hang', 'porch', 'summertime', 'fast', 'review', 'dine', 'taco', 'fake', 'meat', 'tasty', 'bartender', 'margarita', 'taste', 'normal', 'marg', 'strong', 'lack', 'pom', 'juice', 'pineapple', 'salsa', 'delicious', 'chunky', 'pineapple', 'salsa', 'delicious', 'chip', 'crispy', 'bad', 'stale', 'chip', 'restaurant', 'edit', 'change', 'star', 'wasn', 'fabulous', 'way', 'crowded', 'super', 'enjoyable', 'atmosphereit', 'busy', 'go', 'friday', 'evening', 'seat', 'arrangement', 'improve', 'unfortunately', 'sit', 'busy', 'walkway', 'bump', 'bit', 'wish', 'chupacabra', 'stuff', 'maybe', 'story', 'menu', 'miss', 'whoop', 'single', 'sad', 'little', 'bat', 'hang', 'ceiling', 'enjoy', 'company', 'friendly', 'goat', 'eat', 'chupacabra', 'festive', 'want', 'carnage', 'dine', 'maybe', 'butcher', 'paper', 'table', 'paper', 'placemat', 'patron', 'draw', 'chupacabra', 'picture', 'chupacabra', 'el', 'chupacabra', 'cozy', 'fun', 'atmosphere', 'crowd', 'reservation', 'wait', 'list', 'sign', 'great', 'margarita', 'affordable', 'tasty', 'food', 'good', 'vegetarian', 'omnivore', 'alike', 'stop', 'check', 'small', 'busy', 'list', 'rarely', 'actually', 'pay', 'attention', 'waitress', 'care', 'attitude', 'beer', 'cold', 'food', 'doesn', 'cause', 'salmonella', 'people', 'waitress', 'little', 'attentive', 'don', 'away', 'star', 'add', 'good', 'tattoo', 'low', 'expectation', 'word', 'mouth', 'want', 'chip', 'salsa', 'stat', 'guac', 'stat', 'margs', 'stat', 'bring', 'triple', 'threat', 'hard', 'furrowed', 'brow', 'face', 'need', 'food', 'need', 'casual', 'get', 'cool', 'little', 'house', 'greenwood', 'porch', 'patio', 'indoor', 'decor', 'scream', 'dia', 'muertos', 'share', 'taco', 'shrimp', 'order', 'special', 'smoked', 'salmon', 'shrimp', 'runner', 'fave', 'unpredictably', 'spicy', 'bite', 'nice', 'tasty', 'little', 'shrunken', 'sucker', 'hard', 'find', 'salmon', 'hand', 'smack', 've', 'salmon', 'taco', 'awesome', 'avocado', 'addition', 'veggie', 'love', 'service', 'perfectly', 'punctual', 'waitress', 'stylish', 'friendly', 'margarita', 'refreshing', 'tasty', 'strong', 'bode', 'out', 'overall', 'good', 'dinner', 'recommend', 'low', 'key', 'fun', 'lively', 'night', 'bad', 'food', 'pretty', 'good', 'service', 'fine', 'decent', 'price', 'atmosphere', 'interesting', 'big', 'fan', 'place', 'great', 'location', 'bartender', 'friendly', 'jukebox', 'favorite', 'time', 'fill', 'punk', 'metal', 'don', 'food', 'great', 'order', 'carne', 'asada', 'burrito', 'friggin', 'love', 'cheap', 'drink', 'happy', 'hour', 'late', 'night', 'special', 'himsa', 'rip', 've', 'good', 'time', 'bring', 'star', 'especially', 'think', 'time', 'past', 'seriously', 'doubt', 'come', 'anymore', 'know', 'mexican', 'place', 'close', 'home', 'el', 'chupa', 'fact', 'time', 've', 'want', 'don', 'wrong', 'food', 'bad', 'great', 'well', 'food', 'atmosphere', 'dandy', 've', 'like', 'coziness', 'decor', 'warm', 'day', 'pleasant', 'inside', 'door', 'open', 'deck', 'outside', 'drink', 'real', 'ass', 'kicker', 'realize', 'margarita', 'cut', 'blame', 'fact', 've', 'find', 'margarita', 'taste', 'good', 'el', 'chupa', 'doesn', 'stand', 'chance', 'past', 'sheer', 'alcohol', 'hold', 'couple', 'time', 'yesterday', 'try', 'mojito', 'fine', 'taste', 'tasty', 'certainly', 'alcohol', 'service', 'wasn', 'horrible', 'start', 'bumpily', 'lunchmate', 'simultaneously', 'wtf', 'moment', 'aloud', 'table', 'visit', 'server', 'time', 'wait', 'patiently', 'fold', 'menu', 'order', 'take', 'show', 'pretty', 'timely', 'fashion', 'arrive', 'time', 'order', 'special', 'time', 'order', 'take', 'clock', 'come', 'go', 'special', 'sum', 'suppose', 'want', 'wouldn', 'bother', 'sorry', 'chupacabra', 'honeymoon', 'place', 'try', 'lot', 'fun', 'watch', 'crowd', 'food', 'good', 'homemade', 'sauce', 'find', 'table', 'chip', 'nachos', 'world', 'wish', 'sell', 'home', 'use', 'actually', 'deck', 'spring', 'summer', 'early', 'fall', 'especially', 'hot', 'summer', 'day', 'great', 'wait', 'time', 'popular', 'cold', 'beer', 'great', 'food', 'wrong', 'price', 'reasonable', 'fun', 'atmosphere', 'come', 'expect', 'college', 'area', 'don', 'mean', 'negatively', 'crowd', 'look', 'young', 'professional', 'staff', 'friendly', 'service', 'quick', 'food', 'good', 'amazing', 'mexican', 'food', 'margarita', 'good', 'complaint', 'dessert', 'fry', 'tortilla', 'cinnamon', 'honey', 'good', 'hadn', 'particular', 'dessert', 'maybe', 'don', 'dessert', 'definitely', 'wouldn', 'order', 'star', 'time', 'favorite', 'mexican', 'food', 'joint', 'chipotle', 'el', 'chupacabre', 'chipotle', 'mcdonald', 'own', 'chain', 'locate', 'mile', 'house', 'el', 'chupe', 'indepentantly', 'own', 'locate', 'neighborhood', 'pick', 'later', 'good', 'pool', 'free', 'jukebox', 'tecate', 'great', 'selection', 'hot', 'sauce', 'good', 'price', 'sure', 'burrito', 'love', 'place', 'good', 'rating', 'service', 'terrible', 'order', 'wrong', 'time', 'mean', 'order', 'wait', 'patiently', 'friend', 'nom', 'away', 'tasty', 'burrito', 'clear', 'server', 'item', 'order', 'food', 'allergy', 'bring', 'burrito', 'fill', 'ingredient', 'eat', 'problem', 'burritos', 'menu', 'oddly', 'name', 'basic', 'regular', 'suspiciously', 'close', 'synonym', 'think', 'new', 'item', 'name', 'help', 'order', 'basic', 'regular', 'serve', 'give', 'star', 'wait', 'minute', 'burrito', 'isn', 'big', 'deal', 'night', 'kicker', 'boyfriend', 'order', 'fake', 'meat', 'burrito', 'takeout', 'tell', 'fake', 'meat', 'say', 'meatless', 'fine', 'get', 'burrito', 'label', 'meat', 'ride', 'bike', 'home', 'hand', 'burrito', 'unwrapped', 'pleasantly', 'surprised', 'find', 'stuff', 'chicken', 'eat', 'meat', 'toss', 'bummer', 'absolutely', 'adore', 'food', 'marg', 'fake', 'meat', 'good', 'need', 'step', 'game', 'far', 'service', 'go', 'great', 'place', 'come', 'anytime', 'vote', 'star', 'guess', 'come', 'enjoy', 'company', 'food', 'go', 'complain', 'service', 'place', 'pay', 'join', 'crowd', 'fast', 'food', 'crap', 'shack', 'food', 'great', 'home', 'sauce', 'good', 'love', 'barrel', 'salsa', 'pine', 'apple', 'low', 'key', 'inexpensive', 'delicious', 'mexican', 'food'], tags=[2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs.tagdocs[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build word embedding using Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = multiprocessing.cpu_count()\n",
    "word_model = Word2Vec(all_docs.doc_words,\n",
    "                      min_count=2,\n",
    "                      size=100,\n",
    "                      window=5,\n",
    "                      workers=workers,\n",
    "                      iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38977, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.7647111 , -0.73086184, -1.2468382 , -1.0027946 , -0.96313715,\n",
       "        0.9111134 ,  0.65977895,  3.5456011 , -0.02235585,  1.6440451 ,\n",
       "       -0.0661039 ,  0.41211852, -0.19577555,  0.1812265 ,  1.5138743 ,\n",
       "        0.02916883,  0.4625483 , -1.3284774 , -0.45937747, -1.6949239 ,\n",
       "        1.2153699 ,  4.196206  , -0.50019646,  0.48818356, -0.6409747 ,\n",
       "        1.5496792 ,  1.1308266 , -2.791238  , -0.7878722 ,  1.9967105 ,\n",
       "       -2.0945165 ,  2.8918045 , -2.4257357 , -0.78464067, -2.8459082 ,\n",
       "        4.979463  , -2.870692  ,  1.8776709 , -0.87444013, -0.9911716 ,\n",
       "       -4.8545923 , -0.29963732,  0.27686313, -2.1057916 ,  1.8179989 ,\n",
       "        1.1317976 ,  1.8244607 , -2.3895843 ,  1.934337  , -0.9373677 ,\n",
       "        2.4383726 ,  1.4679741 , -0.45419896, -0.39970812, -1.4040339 ,\n",
       "        0.5939909 ,  0.5153689 ,  0.71926403,  1.5762645 , -0.29474178,\n",
       "       -0.35648167,  0.00639748,  1.3986342 ,  0.8788819 , -0.4781381 ,\n",
       "        3.0308967 ,  1.1946028 , -0.2747328 ,  2.299122  ,  0.2637879 ,\n",
       "        0.07607791,  1.365188  , -0.55783033, -2.1623447 ,  1.6285464 ,\n",
       "       -0.7563248 ,  2.9683392 , -0.20913929,  0.05560299,  0.6553585 ,\n",
       "        0.09101417, -0.39400128, -0.70904267, -2.427884  ,  0.21857798,\n",
       "        0.8122631 ,  0.32033026,  0.79379797,  0.12037044,  0.6374975 ,\n",
       "        0.5543785 , -0.4400709 ,  4.591583  ,  2.1465614 ,  0.00992613,\n",
       "       -2.4494958 , -0.30629474, -1.6794864 , -0.50620145, -0.17750408],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.wv.syn0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## averaging word embedding in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute average owing to no vector for []\n"
     ]
    }
   ],
   "source": [
    "from UtilWordEmbedding import MeanEmbeddingVectorizer\n",
    "\n",
    "mean_vec_tr = MeanEmbeddingVectorizer(word_model)\n",
    "doc_vec = mean_vec_tr.transform(all_docs.doc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13299, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(dir_path,'doc_vec.csv'), doc_vec, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding_df = df.join(pd.DataFrame(doc_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = mean_embedding_df[mean_embedding_df[\"labels\"] != \"[None]\" ]\n",
    "test_df = mean_embedding_df[mean_embedding_df[\"labels\"] == \"[None]\" ]\n",
    "X_train, y_train =train_df.drop(['text', 'labels'], axis=1), train_df[\"labels\"]\n",
    "X_test, y_test =test_df.drop(['text', 'labels'], axis=1), test_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(np.array(X_train), label=np.array(y_train))\n",
    "dtest = xgb.DMatrix(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier()\n",
    "# model.fit(np.array(X_train), np.array(y_train))\n",
    "# y_pred = model.predict(np.array(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "bst = xgb.train(param, dtrain, 10)\n",
    "y_pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./average_word2vec_predictions.out', y_pred, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 202)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1: 0.7027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 1s 1ms/step - loss: 0.6934 - f1_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 0s 38us/step - loss: 0.6933 - f1_m: 0.0000e+00\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 0s 37us/step - loss: 0.6933 - f1_m: 0.0000e+00\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 0s 39us/step - loss: 0.6932 - f1_m: 0.0000e+00\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 0s 41us/step - loss: 0.6933 - f1_m: 0.0000e+00\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 0s 41us/step - loss: 0.6933 - f1_m: 0.0000e+00\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 0s 36us/step - loss: 0.6933 - f1_m: 0.0000e+00\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 0s 32us/step - loss: 0.6932 - f1_m: 0.0000e+00\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 0s 32us/step - loss: 0.6932 - f1_m: 0.0000e+00\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 0s 34us/step - loss: 0.6932 - f1_m: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=202, activation='softmax'))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[f1_m])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./average_word2vec_predictions_dl.out', y_pred, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
